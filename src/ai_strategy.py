# ============================================
# íŒŒì¼ëª…: src/ai_strategy.py
# ì„¤ëª…: XGBoost / LightGBM ê¸°ë°˜ AI ë§¤ë§¤ ì „ëµ
# 
# ê¸°ëŠ¥:
# - XGBoost / LightGBM ëª¨ë¸ í•™ìŠµ
# - ì¢…ëª© ì˜ˆì¸¡ (ë‹¤ìŒ ì£¼ +3% í™•ë¥ )
# - Top N ì¢…ëª© ì„ ì •
# - ì•™ìƒë¸” (ë‘ ëª¨ë¸ ê²°í•©)
# ============================================

import pandas as pd
import numpy as np
import pickle
import os
from datetime import datetime

# XGBoost
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸ XGBoost ì„¤ì¹˜ í•„ìš”: pip install xgboost")

# LightGBM
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("âš ï¸ LightGBM ì„¤ì¹˜ í•„ìš”: pip install lightgbm")

# sklearn
try:
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import (
        accuracy_score, 
        precision_score, 
        recall_score, 
        f1_score,
        confusion_matrix,
        classification_report
    )
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ scikit-learn ì„¤ì¹˜ í•„ìš”: pip install scikit-learn")


# ============================================
# [1] ì„¤ì •
# ============================================

# ëª¨ë¸ íŒŒë¼ë¯¸í„° (ìµœì í™”ëœ ê°’ - n_estimators=1000)
XGB_PARAMS = {
    'objective': 'binary:logistic',  # ì´ì§„ ë¶„ë¥˜
    'eval_metric': 'logloss',
    'max_depth': 4,                  # íŠ¸ë¦¬ ê¹Šì´ (ë‹¨ìˆœí™”)
    'learning_rate': 0.03,           # í•™ìŠµë¥ 
    'n_estimators': 1000,            # â­ íŠ¸ë¦¬ ê°œìˆ˜ (ìµœì ê°’!)
    'min_child_weight': 5,           # ê³¼ì í•© ë°©ì§€
    'subsample': 0.7,                # ë°ì´í„° ìƒ˜í”Œë§
    'colsample_bytree': 0.7,         # í”¼ì²˜ ìƒ˜í”Œë§
    'scale_pos_weight': 3,           # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
    'random_state': 42,
    'n_jobs': -1,                    # ë³‘ë ¬ ì²˜ë¦¬
}

# LightGBM íŒŒë¼ë¯¸í„° (ìµœì í™”ëœ ê°’ - num_leaves=10)
LGB_PARAMS = {
    'objective': 'binary',
    'metric': 'binary_logloss',
    'max_depth': 4,
    'learning_rate': 0.03,
    'n_estimators': 1000,            # â­ íŠ¸ë¦¬ ê°œìˆ˜
    'num_leaves': 10,                # â­ í•µì‹¬! ë‹¨ìˆœí•œ ëª¨ë¸
    'min_child_weight': 5,
    'subsample': 0.7,
    'colsample_bytree': 0.7,
    'scale_pos_weight': 3,
    'random_state': 42,
    'n_jobs': -1,
    'verbose': -1,                   # ë¡œê·¸ ìˆ¨ê¹€
}

# ì¢…ëª© ì„ ì •
TOP_N = 3
ALLOCATIONS = [0.4, 0.3, 0.3]
MIN_PROBABILITY = 0.5  # ìµœì†Œ í™•ë¥  (ì´ìƒì´ì–´ì•¼ ë§¤ìˆ˜)

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ
MODEL_PATH = "models/xgb_model.pkl"


# ============================================
# [2] AI ì „ëµ í´ë˜ìŠ¤
# ============================================

class AIStrategy:
    """
    XGBoost ê¸°ë°˜ AI ë§¤ë§¤ ì „ëµ
    
    ì‚¬ìš© ì˜ˆì‹œ:
        strategy = AIStrategy()
        strategy.train(train_df, feature_cols)
        picks = strategy.predict(test_df, feature_cols)
    """
    
    def __init__(self, params=None, top_n=TOP_N, allocations=ALLOCATIONS, 
                 min_probability=MIN_PROBABILITY):
        """
        ì „ëµ ì´ˆê¸°í™”
        
        Args:
            params: XGBoost íŒŒë¼ë¯¸í„° (Noneì´ë©´ ê¸°ë³¸ê°’)
            top_n: ì„ ì •í•  ì¢…ëª© ìˆ˜
            allocations: ì¢…ëª©ë³„ íˆ¬ì ë¹„ì¤‘
            min_probability: ìµœì†Œ ë§¤ìˆ˜ í™•ë¥ 
        """
        if not XGBOOST_AVAILABLE:
            raise ImportError("XGBoostê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        self.params = params or XGB_PARAMS.copy()
        self.top_n = top_n
        self.allocations = allocations
        self.min_probability = min_probability
        
        self.model = None
        self.feature_cols = None
        self.feature_importance = None
        self.train_metrics = None
    
    # ============================================
    # [3] ëª¨ë¸ í•™ìŠµ
    # ============================================
    
    def train(self, train_df, feature_cols, valid_ratio=0.2):
        """
        XGBoost ëª¨ë¸ í•™ìŠµ
        
        Args:
            train_df: í•™ìŠµ ë°ì´í„°
            feature_cols: í”¼ì²˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
            valid_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        
        Returns:
            dict: í•™ìŠµ ê²°ê³¼ ë©”íŠ¸ë¦­
        """
        print("=" * 60)
        print("XGBoost ëª¨ë¸ í•™ìŠµ")
        print("=" * 60)
        
        self.feature_cols = feature_cols
        
        # ë°ì´í„° ì¤€ë¹„
        X = train_df[feature_cols].values
        y = train_df['label'].values
        
        print(f"í•™ìŠµ ë°ì´í„°: {len(X):,}ê°œ")
        print(f"í”¼ì²˜ ìˆ˜: {len(feature_cols)}")
        print(f"ë¼ë²¨ ë¶„í¬: 0={sum(y==0):,}, 1={sum(y==1):,}")
        
        # í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
        X_train, X_valid, y_train, y_valid = train_test_split(
            X, y, test_size=valid_ratio, random_state=42, stratify=y
        )
        
        print(f"\ní•™ìŠµì…‹: {len(X_train):,}ê°œ")
        print(f"ê²€ì¦ì…‹: {len(X_valid):,}ê°œ")
        
        # ëª¨ë¸ í•™ìŠµ
        print("\nëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        early_stopping = self.params.pop('early_stopping_rounds', 20)
        
        self.model = xgb.XGBClassifier(**self.params)
        
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_valid, y_valid)],
            verbose=False
        )
        
        # ê²€ì¦ ì„±ëŠ¥
        y_pred = self.model.predict(X_valid)
        y_prob = self.model.predict_proba(X_valid)[:, 1]
        
        metrics = {
            'accuracy': accuracy_score(y_valid, y_pred),
            'precision': precision_score(y_valid, y_pred, zero_division=0),
            'recall': recall_score(y_valid, y_pred, zero_division=0),
            'f1': f1_score(y_valid, y_pred, zero_division=0)
        }
        
        self.train_metrics = metrics
        
        print("\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"\nğŸ“Š ê²€ì¦ ì„±ëŠ¥:")
        print(f"  Accuracy:  {metrics['accuracy']:.4f}")
        print(f"  Precision: {metrics['precision']:.4f}")  # ë§¤ìˆ˜ ì‹ í˜¸ ì •í™•ë„
        print(f"  Recall:    {metrics['recall']:.4f}")
        print(f"  F1 Score:  {metrics['f1']:.4f}")
        
        # í”¼ì²˜ ì¤‘ìš”ë„
        self.feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nğŸ” Top 10 ì¤‘ìš” í”¼ì²˜:")
        for i, row in self.feature_importance.head(10).iterrows():
            print(f"  {row['feature']:20} : {row['importance']:.4f}")
        
        return metrics
    
    # ============================================
    # [4] ì˜ˆì¸¡ ë° ì¢…ëª© ì„ ì •
    # ============================================
    
    def predict(self, df, feature_cols=None, date=None):
        """
        ì¢…ëª© ì˜ˆì¸¡ ë° ë§¤ìˆ˜ ì¶”ì²œ
        
        Args:
            df: ì˜ˆì¸¡ìš© ë°ì´í„°
            feature_cols: í”¼ì²˜ ì»¬ëŸ¼ (Noneì´ë©´ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê²ƒ)
            date: íŠ¹ì • ë‚ ì§œë§Œ ì˜ˆì¸¡ (Noneì´ë©´ ì „ì²´)
        
        Returns:
            DataFrame: ì¢…ëª©ë³„ ì˜ˆì¸¡ í™•ë¥ 
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train() ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        feature_cols = feature_cols or self.feature_cols
        
        # íŠ¹ì • ë‚ ì§œ í•„í„°ë§
        if date is not None:
            df = df[df['date'] == pd.Timestamp(date)].copy()
        
        if df.empty:
            return pd.DataFrame()
        
        # ì˜ˆì¸¡
        X = df[feature_cols].values
        probs = self.model.predict_proba(X)[:, 1]
        
        # ê²°ê³¼ ì •ë¦¬
        result = df[['date', 'symbol', 'close']].copy()
        result['probability'] = probs
        result['prediction'] = (probs >= self.min_probability).astype(int)
        
        return result.sort_values('probability', ascending=False)
    
    def select_stocks(self, df, feature_cols=None, date=None):
        """
        ë§¤ìˆ˜í•  ì¢…ëª© ì„ ì • (ëª¨ë©˜í…€ ì „ëµê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)
        
        Args:
            df: ì˜ˆì¸¡ìš© ë°ì´í„°
            feature_cols: í”¼ì²˜ ì»¬ëŸ¼
            date: ì˜ˆì¸¡ ë‚ ì§œ
        
        Returns:
            dict: {
                'picks': [ì¢…ëª© ë¦¬ìŠ¤íŠ¸],
                'scores': [í™•ë¥  ë¦¬ìŠ¤íŠ¸],
                'allocations': [ë¹„ì¤‘ ë¦¬ìŠ¤íŠ¸]
            } ë˜ëŠ” None
        """
        pred_df = self.predict(df, feature_cols, date)
        
        if pred_df.empty:
            return None
        
        # ìµœì†Œ í™•ë¥  ì´ìƒì¸ ì¢…ëª©ë§Œ
        candidates = pred_df[pred_df['probability'] >= self.min_probability]
        
        if candidates.empty:
            return None
        
        # Top N ì„ ì •
        top_picks = candidates.head(self.top_n)
        
        n_picks = len(top_picks)
        if n_picks == 0:
            return None
        
        # ë¹„ì¤‘ ê³„ì‚°
        if n_picks >= 3:
            allocations = self.allocations[:3]
        elif n_picks == 2:
            allocations = [0.5, 0.5]
        elif n_picks == 1:
            allocations = [1.0]
        
        return {
            'picks': top_picks['symbol'].tolist(),
            'scores': top_picks['probability'].tolist(),
            'allocations': allocations[:n_picks],
            'prices': dict(zip(top_picks['symbol'], top_picks['close']))
        }
    
    # ============================================
    # [5] ëª¨ë¸ ì €ì¥/ë¡œë“œ
    # ============================================
    
    def save(self, path=MODEL_PATH):
        """
        ëª¨ë¸ ì €ì¥
        
        Args:
            path: ì €ì¥ ê²½ë¡œ
        """
        if self.model is None:
            raise ValueError("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        save_data = {
            'model': self.model,
            'feature_cols': self.feature_cols,
            'feature_importance': self.feature_importance,
            'train_metrics': self.train_metrics,
            'params': self.params,
            'top_n': self.top_n,
            'allocations': self.allocations,
            'min_probability': self.min_probability,
            'saved_at': datetime.now().isoformat()
        }
        
        with open(path, 'wb') as f:
            pickle.dump(save_data, f)
        
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")
    
    def load(self, path=MODEL_PATH):
        """
        ëª¨ë¸ ë¡œë“œ
        
        Args:
            path: ë¡œë“œ ê²½ë¡œ
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
        
        with open(path, 'rb') as f:
            save_data = pickle.load(f)
        
        self.model = save_data['model']
        self.feature_cols = save_data['feature_cols']
        self.feature_importance = save_data['feature_importance']
        self.train_metrics = save_data['train_metrics']
        self.params = save_data['params']
        self.top_n = save_data['top_n']
        self.allocations = save_data['allocations']
        self.min_probability = save_data['min_probability']
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")
        print(f"  ì €ì¥ ì‹œì : {save_data.get('saved_at', 'Unknown')}")
        print(f"  Precision: {self.train_metrics.get('precision', 0):.4f}")


# ============================================
# [6] í‰ê°€ í•¨ìˆ˜
# ============================================

def evaluate_model(strategy, test_df, feature_cols):
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€
    
    Args:
        strategy: AIStrategy ì¸ìŠ¤í„´ìŠ¤
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„°
        feature_cols: í”¼ì²˜ ì»¬ëŸ¼
    
    Returns:
        dict: í‰ê°€ ë©”íŠ¸ë¦­
    """
    print("=" * 60)
    print("ëª¨ë¸ í‰ê°€ (í…ŒìŠ¤íŠ¸ì…‹)")
    print("=" * 60)
    
    pred_df = strategy.predict(test_df, feature_cols)
    
    y_true = test_df['label'].values
    y_pred = (pred_df['probability'] >= strategy.min_probability).astype(int).values
    y_prob = pred_df['probability'].values
    
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'recall': recall_score(y_true, y_pred, zero_division=0),
        'f1': f1_score(y_true, y_pred, zero_division=0)
    }
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
    print(f"  Accuracy:  {metrics['accuracy']:.4f}")
    print(f"  Precision: {metrics['precision']:.4f}")  # ìŠ¹ë¥ !
    print(f"  Recall:    {metrics['recall']:.4f}")
    print(f"  F1 Score:  {metrics['f1']:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nğŸ“Š Confusion Matrix:")
    print(f"  TN={cm[0,0]:,}  FP={cm[0,1]:,}")
    print(f"  FN={cm[1,0]:,}  TP={cm[1,1]:,}")
    
    # ë§¤ìˆ˜ ì‹ í˜¸ ë¶„ì„
    buy_signals = pred_df[pred_df['prediction'] == 1]
    print(f"\nğŸ“Š ë§¤ìˆ˜ ì‹ í˜¸ ë¶„ì„:")
    print(f"  ì´ ë§¤ìˆ˜ ì‹ í˜¸: {len(buy_signals):,}ê°œ")
    
    if len(buy_signals) > 0:
        actual_wins = test_df.loc[buy_signals.index, 'label'].sum()
        win_rate = actual_wins / len(buy_signals) * 100
        print(f"  ì‹¤ì œ +3% ë‹¬ì„±: {actual_wins:,}ê°œ ({win_rate:.1f}%)")
        
        avg_future_ret = test_df.loc[buy_signals.index, 'future_ret'].mean() * 100
        print(f"  í‰ê·  ìˆ˜ìµë¥ : {avg_future_ret:.2f}%")
    
    return metrics


# ============================================
# [7] LightGBM ì „ëµ í´ë˜ìŠ¤
# ============================================

class LGBStrategy:
    """
    LightGBM ê¸°ë°˜ AI ë§¤ë§¤ ì „ëµ
    
    ì‚¬ìš© ì˜ˆì‹œ:
        strategy = LGBStrategy()
        strategy.train(train_df, feature_cols)
        picks = strategy.predict(test_df, feature_cols)
    """
    
    def __init__(self, params=None, top_n=TOP_N, allocations=ALLOCATIONS, 
                 min_probability=MIN_PROBABILITY):
        """
        ì „ëµ ì´ˆê¸°í™”
        """
        if not LIGHTGBM_AVAILABLE:
            raise ImportError("LightGBMì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        self.params = params or LGB_PARAMS.copy()
        self.top_n = top_n
        self.allocations = allocations
        self.min_probability = min_probability
        
        self.model = None
        self.feature_cols = None
        self.feature_importance = None
        self.train_metrics = None
    
    def train(self, train_df, feature_cols, valid_ratio=0.2):
        """
        LightGBM ëª¨ë¸ í•™ìŠµ
        """
        print("=" * 60)
        print("LightGBM ëª¨ë¸ í•™ìŠµ")
        print("=" * 60)
        
        self.feature_cols = feature_cols
        
        # ë°ì´í„° ì¤€ë¹„
        X = train_df[feature_cols].values
        y = train_df['label'].values
        
        print(f"í•™ìŠµ ë°ì´í„°: {len(X):,}ê°œ")
        print(f"í”¼ì²˜ ìˆ˜: {len(feature_cols)}")
        print(f"ë¼ë²¨ ë¶„í¬: 0={sum(y==0):,}, 1={sum(y==1):,}")
        
        # í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
        X_train, X_valid, y_train, y_valid = train_test_split(
            X, y, test_size=valid_ratio, random_state=42, stratify=y
        )
        
        print(f"\ní•™ìŠµì…‹: {len(X_train):,}ê°œ")
        print(f"ê²€ì¦ì…‹: {len(X_valid):,}ê°œ")
        
        # ëª¨ë¸ í•™ìŠµ
        print("\nëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        self.model = lgb.LGBMClassifier(**self.params)
        
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_valid, y_valid)],
        )
        
        # ê²€ì¦ ì„±ëŠ¥
        y_pred = self.model.predict(X_valid)
        y_prob = self.model.predict_proba(X_valid)[:, 1]
        
        metrics = {
            'accuracy': accuracy_score(y_valid, y_pred),
            'precision': precision_score(y_valid, y_pred, zero_division=0),
            'recall': recall_score(y_valid, y_pred, zero_division=0),
            'f1': f1_score(y_valid, y_pred, zero_division=0)
        }
        
        self.train_metrics = metrics
        
        print("\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"\nğŸ“Š ê²€ì¦ ì„±ëŠ¥:")
        print(f"  Accuracy:  {metrics['accuracy']:.4f}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall:    {metrics['recall']:.4f}")
        print(f"  F1 Score:  {metrics['f1']:.4f}")
        
        # í”¼ì²˜ ì¤‘ìš”ë„
        self.feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nğŸ” Top 10 ì¤‘ìš” í”¼ì²˜:")
        for i, row in self.feature_importance.head(10).iterrows():
            print(f"  {row['feature']:20} : {row['importance']:.4f}")
        
        return metrics
    
    def predict(self, df, feature_cols=None, date=None):
        """
        ì¢…ëª© ì˜ˆì¸¡ ë° ë§¤ìˆ˜ ì¶”ì²œ
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        feature_cols = feature_cols or self.feature_cols
        
        if date is not None:
            df = df[df['date'] == pd.Timestamp(date)].copy()
        
        if df.empty:
            return pd.DataFrame()
        
        X = df[feature_cols].values
        probs = self.model.predict_proba(X)[:, 1]
        
        result = df[['date', 'symbol', 'close']].copy()
        result['probability'] = probs
        result['prediction'] = (probs >= self.min_probability).astype(int)
        
        return result.sort_values('probability', ascending=False)
    
    def select_stocks(self, df, feature_cols=None, date=None):
        """
        ë§¤ìˆ˜í•  ì¢…ëª© ì„ ì •
        """
        pred_df = self.predict(df, feature_cols, date)
        
        if pred_df.empty:
            return None
        
        candidates = pred_df[pred_df['probability'] >= self.min_probability]
        
        if candidates.empty:
            return None
        
        top_picks = candidates.head(self.top_n)
        
        n_picks = len(top_picks)
        if n_picks == 0:
            return None
        
        if n_picks >= 3:
            allocations = self.allocations[:3]
        elif n_picks == 2:
            allocations = [0.5, 0.5]
        elif n_picks == 1:
            allocations = [1.0]
        
        return {
            'picks': top_picks['symbol'].tolist(),
            'scores': top_picks['probability'].tolist(),
            'allocations': allocations[:n_picks],
            'prices': dict(zip(top_picks['symbol'], top_picks['close']))
        }
    
    def save(self, path="models/lgb_model.pkl"):
        """ëª¨ë¸ ì €ì¥"""
        if self.model is None:
            raise ValueError("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        save_data = {
            'model': self.model,
            'feature_cols': self.feature_cols,
            'feature_importance': self.feature_importance,
            'train_metrics': self.train_metrics,
            'params': self.params,
            'saved_at': datetime.now().isoformat()
        }
        
        with open(path, 'wb') as f:
            pickle.dump(save_data, f)
        
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")
    
    def load(self, path="models/lgb_model.pkl"):
        """ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
        
        with open(path, 'rb') as f:
            save_data = pickle.load(f)
        
        self.model = save_data['model']
        self.feature_cols = save_data['feature_cols']
        self.feature_importance = save_data['feature_importance']
        self.train_metrics = save_data['train_metrics']
        self.params = save_data['params']
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")


def evaluate_lgb_model(strategy, test_df, feature_cols):
    """
    LightGBM í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
    """
    print("=" * 60)
    print("LightGBM ëª¨ë¸ í‰ê°€ (í…ŒìŠ¤íŠ¸ì…‹)")
    print("=" * 60)
    
    pred_df = strategy.predict(test_df, feature_cols)
    
    y_true = test_df['label'].values
    y_pred = (pred_df['probability'] >= strategy.min_probability).astype(int).values
    y_prob = pred_df['probability'].values
    
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'recall': recall_score(y_true, y_pred, zero_division=0),
        'f1': f1_score(y_true, y_pred, zero_division=0)
    }
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
    print(f"  Accuracy:  {metrics['accuracy']:.4f}")
    print(f"  Precision: {metrics['precision']:.4f}")
    print(f"  Recall:    {metrics['recall']:.4f}")
    print(f"  F1 Score:  {metrics['f1']:.4f}")
    
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nğŸ“Š Confusion Matrix:")
    print(f"  TN={cm[0,0]:,}  FP={cm[0,1]:,}")
    print(f"  FN={cm[1,0]:,}  TP={cm[1,1]:,}")
    
    buy_signals = pred_df[pred_df['prediction'] == 1]
    print(f"\nğŸ“Š ë§¤ìˆ˜ ì‹ í˜¸ ë¶„ì„:")
    print(f"  ì´ ë§¤ìˆ˜ ì‹ í˜¸: {len(buy_signals):,}ê°œ")
    
    if len(buy_signals) > 0:
        actual_wins = test_df.loc[buy_signals.index, 'label'].sum()
        win_rate = actual_wins / len(buy_signals) * 100
        print(f"  ì‹¤ì œ +3% ë‹¬ì„±: {actual_wins:,}ê°œ ({win_rate:.1f}%)")
        
        avg_future_ret = test_df.loc[buy_signals.index, 'future_ret'].mean() * 100
        print(f"  í‰ê·  ìˆ˜ìµë¥ : {avg_future_ret:.2f}%")
    
    return metrics


# ============================================
# [8] í…ŒìŠ¤íŠ¸
# ============================================

if __name__ == "__main__":
    print("AI Strategy ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    if XGBOOST_AVAILABLE:
        print("âœ… XGBoost ì‚¬ìš© ê°€ëŠ¥")
    else:
        print("âŒ XGBoost ì„¤ì¹˜ í•„ìš”")
    
    if LIGHTGBM_AVAILABLE:
        print("âœ… LightGBM ì‚¬ìš© ê°€ëŠ¥")
    else:
        print("âŒ LightGBM ì„¤ì¹˜ í•„ìš”")
    
    print("\nì‚¬ìš©ë²•:")
    print("  from ai_strategy import AIStrategy, LGBStrategy")
    print("  from ai_strategy import evaluate_model, evaluate_lgb_model")